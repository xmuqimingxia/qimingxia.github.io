<!DOCTYPE html>
<!-- saved from url=(0055)https://www.starlg.cn/TianliangZhang/TianliangZhang.htm -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Tianliang Zhang&#39;s home page">

  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
  <title>Qiming Xia's Homepage--夏启明的个人主页</title>
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body>
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td>
        <img width="160" src="./imgs/qimingxia.jpg" border="3">
      </td>	
      <td width="670">
        <div id="toptitle">
        <h1>Qiming Xia &nbsp; 夏启明<a name="top"></a></h1>
		</div>
        <h3>Ph.D. student at Xiamen University</h3>
        <p>
        <br> Email:
        <a href="xiaqiming@stu.xmu.edu.cn">xiaqiming@stu.xmu.edu.cn</a>		
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	&nbsp;&nbsp;<a href="https://github.com/xmuqimingxia" target="_blank">[Github]</a>
	&nbsp;&nbsp;<a href="https://scholar.google.com/citations?hl=zh-CN&user=A6spPv_n5qUC&view_op=list_works&sortby=pubdate" target="_blank">[Scholar]</a>	
  <!--      &nbsp;&nbsp;<a href="#" target="_blank">[Ph.D. Thesis, in Chinese]</a>		-->
        <br><br></p>
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


<h4>[<a style=" color:#9D849A;" href="#biography">Biography</a>] [<a style=" color:#9D849A;" href="#news">Latest News</a>] [<a style=" color:#9D849A;" href="#publications">Publications</a>] 
[<a style=" color:#9D849A;" href="#activities">Professional Activities</a>] [<a style=" color:#9D849A;" href="#awards">Major Awards</a>] [<a style=" color:#9D849A;" href="#statistics">Statistics</a>]</h4>


<h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <p style="text-indent:2em;"> I am currently pursuing the Ph.D. degree with the School of Informatics, Xiamen University, Xiamen, China. My research interests focus on computer vision and machine learning, particularly in exploring machine learning for autonomous systems. This includes 3D scene understanding, object detection, and other topics related to autonomous driving.
  </p>


<h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>  
  <li> 07/2024: One paper is accepted by ECCV 2024 </li>		
  <li> 02/2024: One paper is accepted by CVPR 2024 </li>	
  <li> 08/2023: One paper is accepted by ICCV 2023 </li>	
  <li> 02/2023: One paper is accepted by TGRS </li>
</ul>


<h2>Publications<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3>Journal</h3>
<table class="pub_table">
  <tbody>

    <tr>
    <td class="pub_td1"> <img src="./imgs/laconv.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Gen Luo</font>, Yiyi Zhou<sup>✉</sup>, Xiaoshuai Sun, Feiyue Huang, Yue Gao, Rongrong Ji
      <br><b>Towards Language-guided Visual Recognition via Dynamic Convolutions</b>
      <br> International Journal of Computer Vision (IJCV) 
      <br> 
    </td>
  </tr>    
  <tr>
    <td class="pub_td1"> <img src="./imgs/simrec.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Gen Luo</font>, Yiyi Zhou<sup>✉</sup>, Jiamu Sun,  Xiaoshuai Sun, Rongrong Ji
      <br><b>A Survivor in the Era of Large-Scale Pretraining: An Empirical Study of One-Stage Referring Expression Comprehension</b>
      <br> IEEE Transactions on Multimedia (TMM)
      <br>
	  [<a href="https://arxiv.org/pdf/2204.07913" target="_blank">arXiv</a>]
	  [<a href="https://github.com/luogen1996/SimREC" target="_blank">code</a>]
    </td>
  </tr>   		  
  <tr>
    <td class="pub_td1"> <img src="./imgs/lwtrans.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Gen Luo</font>, Yiyi Zhou<sup>✉</sup>, Xiaoshuai Sun, Yan Wang, Liujuan Cao, Yongjian Wu, Feiyue Huang, Rongrong Ji
      <br><b>Towards Lightweight Transformer Via Group-Wise Transformation for Vision-and-Language Tasks</b>
      <br>IEEE Transactions on Image Processing (TIP), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/abstract/document/9763437" target="_blank">pdf</a>]	 
      [<a href="https://arxiv.org/pdf/2204.07780" target="_blank">arXiv</a>]	  
      [<a href="https://github.com/luogen1996/LWTransformer" target="_blank">code</a>]                    
    </td>
  </tr>   	 
	  
  <tr>
    <td class="pub_td1"> <img src="./imgs/dasa.png" class="papericon"></td>
    <td class="pub_td2"> Jiayi Ji, Xiaoyang Huang, Xiaoshuai Sun<sup>✉</sup>, Yiyi Zhou, <font color="goldenrod">Gen Luo</font>, Liujuan Cao, Jianzhuang Liu, Ling Shao, Rongrong Ji 
      <br><b>Multi-Branch Distance-Sensitive Self-Attention Network for Image Captioning</b>
      <br>IEEE Transactions on Multimedia (TMM), 2022
      <br>
      [<a href="https://ieeexplore.ieee.org/abstract/document/9761944" target="_blank">pdf</a>] 
    </td>
  </tr>

  <tr>
    <td class="pub_td1"> <img src="./imgs/realgin.png" class="papericon"></td>
    <td class="pub_td2"> Yiyi Zhou, Rongrong Ji<sup>✉</sup>, <font color="goldenrod">Gen Luo</font>, Xiaoshuai Sun, Jinsong Su, Xinghao Ding, Chia-Wen Lin, Qi Tian
      <br><b>A Real-Time Global Inference Network for One-Stage Referring Expression Comprehension</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2021
      <br>
      [<a href="https://ieeexplore.ieee.org/abstract/document/9470913" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/pdf/1912.03478" target="_blank">arXiv</a>]
      [<a href="https://github.com/luogen1996/Real-time-Global-Inference-Network" target="_blank">code</a>]
    </td>
  </tr>

  </tbody>
</table>


<h3>Conference</h3>
<table class="pub_table">
  <tbody>
       <tr>
    <td class="pub_td1"> <img src="./imgs/lavin.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Gen Luo</font>, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, Rongrong Ji<sup>✉</sup>
      <br><b>Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models</b>
      <br>NeurIPS, 2023
      <br>
	  [<a href="https://arxiv.org/pdf/2305.15023.pdf" target="_blank">paper</a>]
	  [<a href="https://luogen1996.github.io/lavin/" target="_blank">project</a>]
    </td>
    </tr>
	  
       <tr>
    <td class="pub_td1"> <img src="./imgs/refclip.png" class="papericon"></td>
    <td class="pub_td2"> Lei Jin*, <font color="goldenrod">Gen Luo*(Equal Contribution)</font>, Yiyi Zhou<sup>✉</sup>, Xiaoshuai Sun, Guannan Jiang, Annan Shu, Rongrong Ji
      <br><b>RefCLIP: A Universal Teacher for Weakly Supervised Referring Expression Comprehension</b>
      <br>CVPR, 2023
      <br>
	  [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_RefCLIP_A_Universal_Teacher_for_Weakly_Supervised_Referring_Expression_Comprehension_CVPR_2023_paper.pdf" target="_blank">paper</a>]
	  [<a href="https://refclip.github.io" target="_blank">project</a>]
    </td>
    </tr>

     <tr>
    <td class="pub_td1"> <img src="./imgs/refteacher.png" class="papericon"></td>
    <td class="pub_td2">Jiamu Sun, <font color="goldenrod">Gen Luo</font>, Yiyi Zhou<sup>✉</sup>, Xiaoshuai Sun, Guannan Jiang, Zhiyu Wang, Rongrong Ji
      <br><b>RefTeacher: A Strong Baseline for Semi-Supervised Referring Expression Comprehension</b>
      <br>CVPR, 2023
      <br>
	  [<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_RefTeacher_A_Strong_Baseline_for_Semi-Supervised_Referring_Expression_Comprehension_CVPR_2023_paper.pdf" target="_blank">paper</a>]
	  [<a href="https://refteacher.github.io/" target="_blank">project</a>]
    </td>
    </tr>

    <tr>
    <td class="pub_td1"> <img src="./imgs/seqtr.png" class="papericon"></td>
    <td class="pub_td2">Chaoyang Zhu, Yiyi Zhou, Yunhang Shen, <font color="goldenrod">Gen Luo</font>, Xingjia Pan, Mingbao Lin, Chao Chen, Liujuan Cao<sup>✉</sup>, Xiaoshuai Sun, Rongrong Ji
      <br><b>SeqTR: A Simple yet Universal Network for Visual Grounding</b>
      <br>ECCV, 2022, <font color="red">Oral (Top 2.7%)</font>
      <br>
	  [<a href="https://arxiv.org/pdf/2203.16265" target="_blank">arXiv</a>]
	  [<a href="https://github.com/sean-zhuh/SeqTR" target="_blank">code</a>]
    </td>
  </tr>   

  <tr>
    <td class="pub_td1"> <img src="./imgs/active.png" class="papericon"></td>
    <td class="pub_td2"> Peng Mi, Jianghang Lin, Yiyi Zhou, Yunhang Shen, <font color="goldenrod">Gen Luo</font>, Xiaoshuai Sun, Liujuan Cao, Rongrong Fu, Qiang Xu, Rongrong Ji<sup>✉</sup>
      <br><b>Active Teacher for Semi-Supervised Object Detection</b>
      <br>CVPR, 2022
      <br>
      [<a href="#" target="_blank">pdf coming</a>] 
      [<a href="https://github.com/HunterJ-Lin/ActiveTeacher" target="_blank">code</a>]
    </td>
  </tr>

  <tr>
    <td class="pub_td1"> <img src="./imgs/get.png" class="papericon"></td>
    <td class="pub_td2"> Jiayi Ji, Yunpeng Luo, Xiaoshuai Sun<sup>✉</sup>, Fuhai Chen, <font color="goldenrod">Gen Luo</font>, Yongjian Wu, Yue Gao, Rongrong Ji
      <br><b>Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network </b>
      <br>AAAI, 2021
      <br>
      [<a href="https://www.aaai.org/AAAI21Papers/AAAI-1324.JiJ.pdf" target="_blank">pdf</a>    
    </td>
  </tr>

  <tr>
    <td class="pub_td1"> <img src="./imgs/agan.png" class="papericon"></td>
    <td class="pub_td2"> Yiyi Zhou, Rongrong Ji<sup>✉</sup>, Xiaoshuai Sun,  <font color="goldenrod">Gen Luo</font>, Xiaopeng Hong, Jinsong Su, Xinghao Ding, Ling Shao
      <br><b>K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering</b>
      <br>ACM MM, 2020, <font color="red">Oral (Top 8.9%)</font>
      <br>
      [<a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413998" target="_blank">pdf</a>]                 
    </td>
  </tr>
	  
  <tr>
    <td class="pub_td1"> <img src="./imgs/cgan.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Gen Luo</font>, Yiyi Zhou<sup>✉</sup>, Rongrong Ji, Xiaoshuai Sun, Jinsong Su, Chia-Wen Lin, Qi Tian
      <br><b>Cascade Grouped Attention Network for Referring Expression Segmentation</b>
      <br>ACM MM, 2020, <font color="red">Oral (Top 8.9%)</font>
      <br>
      [<a href="https://dl.acm.org/doi/abs/10.1145/3394171.3414006" target="_blank">pdf</a>]     
    </td>
  </tr>

  <tr>
    <td class="pub_td1"> <img src="./imgs/mcn.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Gen Luo</font>, Yiyi Zhou, Xiaoshuai Sun, Liujuan Cao, Chenglin Wu, Cheng Deng, Rongrong Ji<sup>✉</sup>
      <br><b>Multi-Task Collaborative Network for Joint Referring Expression Comprehension and Segmentation</b>
      <br>CVPR, 2020, <font color="red">Oral (Top 5%)</font>
      <br>
      [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Luo_Multi-Task_Collaborative_Network_for_Joint_Referring_Expression_Comprehension_and_Segmentation_CVPR_2020_paper.pdf" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/2003.08813" target="_blank">arXiv</a>]
      [<a href="https://github.com/luogen1996/MCN" target="_blank">code</a>]
    </td>
  </tr>


  </tbody>
</table>




<h2>Professional Activities<a name="activities"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
    <li> Conference Reviewer: CVPR 2022, ECCV 2022, CVPR2023</li> 
</ul>

<h2>Major Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
    <li>  National Scholarship, China, 2020  </li> 
    <li>  Xiamen University Scholarship, 2019  </li>
</ul>


</div>
</div>
</body>
</html>
